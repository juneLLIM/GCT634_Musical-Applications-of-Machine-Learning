{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X89_C13TX8Vt"
   },
   "source": [
    "# Symbolic Music Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgKVNW5pYGSS"
   },
   "source": [
    "The goal of this homework is understanding a simple RNN-based musical langauge model to generate performance MIDI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2R73XYcYWGi"
   },
   "source": [
    "## Download the MIDI file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M987IdwlYYHb"
   },
   "source": [
    "We are going to use a single MIDI file from Saarland Music Data (SMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5893,
     "status": "ok",
     "timestamp": 1747006439902,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "m0lTo9eAXq8b",
    "outputId": "45e5f1e6-9b8c-4ccb-9917-cf7b0440bedf"
   },
   "outputs": [],
   "source": [
    "# # Download the audio files\n",
    "# !gdown 1ORJ5ZYLYkL4NYLJXtcElKQRstxKL13NU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1747006439905,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "dcqjfqwEX8DC"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !unzip gct634-SMD-MIDI.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FU1KRA0Xkm_p"
   },
   "source": [
    "## Check the MIDI files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6octDXOClrQa"
   },
   "source": [
    "Install python packages to handle MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36687,
     "status": "ok",
     "timestamp": 1747006476702,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "JAjOiLrVktrz"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !sudo apt install -y fluidsynth\n",
    "# !pip install --upgrade pyfluidsynth\n",
    "# !pip install pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJlWVaIIr_os"
   },
   "source": [
    "Open an example of the MIDI files and inspect the notes events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1747006477555,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "U7a9lbgusDc0",
    "outputId": "a2a3b100-b335-415f-9aa9-86279f012b57"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "def midi_to_notes(pm) -> pd.DataFrame:\n",
    "  instrument = pm.instruments[0]\n",
    "  notes = collections.defaultdict(list)\n",
    "\n",
    "  # Sort the notes by start time\n",
    "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "  prev_start = sorted_notes[0].start\n",
    "\n",
    "  for note in sorted_notes:\n",
    "    start = note.start\n",
    "    end = note.end\n",
    "    notes['pitch'].append(note.pitch)\n",
    "    notes['start'].append(start)\n",
    "    notes['end'].append(end)\n",
    "    notes['step'].append(start - prev_start)\n",
    "    notes['duration'].append(end - start)\n",
    "    notes['velocity'].append(note.velocity)\n",
    "    prev_start = start\n",
    "\n",
    "  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})\n",
    "\n",
    "midi_file = 'gct634-SMD-MIDI/Bach_BWV888-01_008_20110315-SMD.mid'\n",
    "pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "raw_notes = midi_to_notes(pm)\n",
    "raw_notes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VDm1SrLl3bQ"
   },
   "source": [
    "Let's listen to the MIDI file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1747006480379,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "ReyYGuoxkvId",
    "outputId": "75e635fb-2ea4-4384-c308-df29ae01cbfb"
   },
   "outputs": [],
   "source": [
    "import fluidsynth\n",
    "import pretty_midi\n",
    "import IPython.display as ipd\n",
    "\n",
    "sr = 44100\n",
    "pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "synth_audio = pm.fluidsynth(fs=sr)\n",
    "\n",
    "# play the 10-sec segment from the beginning\n",
    "synth_audio_seg = synth_audio[:10*sr]\n",
    "ipd.Audio(synth_audio_seg, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMoclSFJiZCv"
   },
   "source": [
    "## MIDI-Like Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQmoBmXsife-"
   },
   "source": [
    "\"EventSeq\" is the core class that implements the MIDI-Like Tokenizer. It takes MIDI note messages and tokenize them into four classes of tokens (NOTE_ON, NOTE_OFF, VELOCITY, and TIME_SHIFT). The code is quite long. Let's try to under stand a little by a little.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747006480390,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "mwODJYWV0o66"
   },
   "outputs": [],
   "source": [
    "from pretty_midi import PrettyMIDI, Note, Instrument\n",
    "\n",
    "USE_VELOCITY = 1\n",
    "DEFAULT_VELOCITY = 64\n",
    "DEFAULT_NOTE_LENGTH = 1\n",
    "MIN_NOTE_LENGTH = 0.05\n",
    "\n",
    "class Event:\n",
    "    def __init__(self, type, time, value):\n",
    "        self.type = type\n",
    "        self.time = time\n",
    "        self.value = value\n",
    "\n",
    "class EventSeq:\n",
    "    pitch_range = range(21, 109)\n",
    "    velocity_range = range(21, 109)\n",
    "    velocity_steps = 32\n",
    "    time_shift_bins = 1.15 ** np.arange(32) / 65\n",
    "\n",
    "    @staticmethod\n",
    "    def from_note_seq(notes):\n",
    "        note_events = []\n",
    "        if USE_VELOCITY:\n",
    "            velocity_bins = EventSeq.get_velocity_bins()\n",
    "\n",
    "        for note in notes:\n",
    "            if note.pitch in EventSeq.pitch_range:\n",
    "                if USE_VELOCITY:\n",
    "                    velocity = note.velocity\n",
    "                    velocity = max(velocity, EventSeq.velocity_range.start)\n",
    "                    velocity = min(velocity, EventSeq.velocity_range.stop - 1)\n",
    "                    velocity_index = np.searchsorted(velocity_bins, velocity)\n",
    "                    note_events.append(Event('velocity', note.start, velocity_index))\n",
    "\n",
    "                pitch_index = note.pitch - EventSeq.pitch_range.start\n",
    "                note_events.append(Event('note_on', note.start, pitch_index))\n",
    "                note_events.append(Event('note_off', note.end, pitch_index))\n",
    "\n",
    "        note_events.sort(key=lambda event: event.time)  # stable\n",
    "        events = []\n",
    "\n",
    "        for i, event in enumerate(note_events):\n",
    "            events.append(event)\n",
    "\n",
    "            if event is note_events[-1]:\n",
    "                break\n",
    "\n",
    "            interval = note_events[i + 1].time - event.time\n",
    "            shift = 0\n",
    "\n",
    "            while interval - shift >= EventSeq.time_shift_bins[0]:\n",
    "                index = np.searchsorted(EventSeq.time_shift_bins,\n",
    "                                        interval - shift, side='right') - 1\n",
    "                events.append(Event('time_shift', event.time + shift, index))\n",
    "                shift += EventSeq.time_shift_bins[index]\n",
    "\n",
    "        return EventSeq(events)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_array(event_indeces):\n",
    "        time = 0\n",
    "        events = []\n",
    "        for event_index in event_indeces:\n",
    "            for event_type, feat_range in EventSeq.feat_ranges().items():\n",
    "                if feat_range.start <= event_index < feat_range.stop:\n",
    "                    event_value = event_index - feat_range.start\n",
    "                    events.append(Event(event_type, time, event_value))\n",
    "                    if event_type == 'time_shift':\n",
    "                        time += EventSeq.time_shift_bins[event_value]\n",
    "                    break\n",
    "\n",
    "        return EventSeq(events)\n",
    "\n",
    "    @staticmethod\n",
    "    def dim():\n",
    "        return sum(EventSeq.feat_dims().values())\n",
    "\n",
    "    @staticmethod\n",
    "    def feat_dims():\n",
    "        feat_dims = collections.OrderedDict()\n",
    "        feat_dims['note_on'] = len(EventSeq.pitch_range)\n",
    "        feat_dims['note_off'] = len(EventSeq.pitch_range)\n",
    "        if USE_VELOCITY:\n",
    "          feat_dims['velocity'] = EventSeq.velocity_steps\n",
    "        feat_dims['time_shift'] = len(EventSeq.time_shift_bins)\n",
    "        return feat_dims\n",
    "\n",
    "    @staticmethod\n",
    "    def feat_ranges():\n",
    "        offset = 0\n",
    "        feat_ranges = collections.OrderedDict()\n",
    "        for feat_name, feat_dim in EventSeq.feat_dims().items():\n",
    "            feat_ranges[feat_name] = range(offset, offset + feat_dim)\n",
    "            offset += feat_dim\n",
    "        return feat_ranges\n",
    "\n",
    "    @staticmethod\n",
    "    def get_velocity_bins():\n",
    "        n = EventSeq.velocity_range.stop - EventSeq.velocity_range.start\n",
    "        return np.arange(\n",
    "            EventSeq.velocity_range.start,\n",
    "            EventSeq.velocity_range.stop,\n",
    "            n / (EventSeq.velocity_steps - 1))\n",
    "\n",
    "    def __init__(self, events=[]):\n",
    "        for event in events:\n",
    "            assert isinstance(event, Event)\n",
    "\n",
    "        self.events = copy.deepcopy(events)\n",
    "\n",
    "        # compute event times again\n",
    "        time = 0\n",
    "        for event in self.events:\n",
    "            event.time = time\n",
    "            if event.type == 'time_shift':\n",
    "                time += EventSeq.time_shift_bins[event.value]\n",
    "\n",
    "    def to_note_seq(self):\n",
    "        time = 0\n",
    "        notes = []\n",
    "\n",
    "        velocity = DEFAULT_VELOCITY\n",
    "        velocity_bins = EventSeq.get_velocity_bins()\n",
    "\n",
    "        last_notes = {}\n",
    "\n",
    "        for event in self.events:\n",
    "            if event.type == 'note_on':\n",
    "                pitch = event.value + EventSeq.pitch_range.start\n",
    "                note = Note(velocity, pitch, time, None)\n",
    "                notes.append(note)\n",
    "                last_notes[pitch] = note\n",
    "\n",
    "            elif event.type == 'note_off':\n",
    "                pitch = event.value + EventSeq.pitch_range.start\n",
    "\n",
    "                if pitch in last_notes:\n",
    "                    note = last_notes[pitch]\n",
    "                    note.end = max(time, note.start + MIN_NOTE_LENGTH)\n",
    "                    del last_notes[pitch]\n",
    "\n",
    "            elif event.type == 'velocity':\n",
    "                index = min(event.value, velocity_bins.size - 1)\n",
    "                velocity = velocity_bins[index]\n",
    "\n",
    "            elif event.type == 'time_shift':\n",
    "                time += EventSeq.time_shift_bins[event.value]\n",
    "\n",
    "        for note in notes:\n",
    "            if note.end is None:\n",
    "                note.end = note.start + DEFAULT_NOTE_LENGTH\n",
    "\n",
    "            note.velocity = int(note.velocity)\n",
    "\n",
    "        return notes\n",
    "\n",
    "    def to_array(self):\n",
    "        feat_idxs = EventSeq.feat_ranges()\n",
    "        idxs = [feat_idxs[event.type][event.value] for event in self.events]\n",
    "        dtype = np.uint8 if EventSeq.dim() <= 256 else np.uint16\n",
    "        return np.array(idxs, dtype=dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6jELAo1qle-"
   },
   "source": [
    "Let's load the MIDI file and tokenize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1747006480402,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "inYNitililuP",
    "outputId": "89d967e7-00ee-4ff1-e82e-138aad79dce7"
   },
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import copy, itertools, collections\n",
    "\n",
    "midi_file = 'gct634-SMD-MIDI/Bach_BWV888-01_008_20110315-SMD.mid'\n",
    "pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "instrument = pm.instruments[0]\n",
    "sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "\n",
    "# shift the first note to 0 sec\n",
    "time_shift = sorted_notes[0].start\n",
    "for note in sorted_notes:\n",
    "  note.start -= time_shift\n",
    "  note.end -= time_shift\n",
    "\n",
    "# print out note sequences for checking\n",
    "for i in range(10):\n",
    "  print(sorted_notes[i])\n",
    "\n",
    "# translates the note sequences into the four classes (NOTE_ON, NOTE_OFF, VELOCITY, and TIME_SHIFT) of events.\n",
    "event_seq = EventSeq.from_note_seq(sorted_notes)\n",
    "\n",
    "# encodes the four classes of events into token indices.\n",
    "event_data = event_seq.to_array()\n",
    "\n",
    "print(\"--- tokens ---\")\n",
    "print(event_data[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MrRgTzsGrK"
   },
   "source": [
    "Let's convert the token indices back to MIDI note events.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1747006480413,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "XKDF9nkf0orV",
    "outputId": "ed5b900e-debc-405f-9aea-f4005e68a070"
   },
   "outputs": [],
   "source": [
    "event_seq = EventSeq.from_array(event_data)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "for i in range(10):\n",
    "  print(output_notes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eUCKwzesqYU"
   },
   "source": [
    "The MIDI note events have changed a little. Why? Let's listen to them. It's quite subtle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1509,
     "status": "ok",
     "timestamp": 1747006481920,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "97L6EgU2DwwM",
    "outputId": "bda52464-39c3-475f-bea4-1d08a341b8ed"
   },
   "outputs": [],
   "source": [
    "DEFAULT_RESOLUTION = 220\n",
    "DEFAULT_TEMPO = 120\n",
    "DEFAULT_SAVING_PROGRAM = 1\n",
    "\n",
    "# make a prettyMIDI object\n",
    "midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "midi.instruments.append(inst)\n",
    "\n",
    "synth_audio = midi.fluidsynth(fs=sr)\n",
    "synth_audio_seg = synth_audio[:10*sr]\n",
    "ipd.Audio(synth_audio_seg, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endV8XCk412B"
   },
   "source": [
    "## Preprocessing MIDI files\n",
    "Once you understand the tokenization, let's store the tokenized MIDI files as separate token files(\".data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3176,
     "status": "ok",
     "timestamp": 1747006485106,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "r590ASgN42J1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def find_files_by_extensions(root, exts=[]):\n",
    "    def _has_ext(name):\n",
    "        if not exts:\n",
    "            return True\n",
    "        name = name.lower()\n",
    "        for ext in exts:\n",
    "            if name.endswith(ext):\n",
    "                return True\n",
    "        return False\n",
    "    for path, _, files in os.walk(root):\n",
    "        for name in files:\n",
    "            if _has_ext(name):\n",
    "                yield os.path.join(path, name)\n",
    "\n",
    "# Load MIDI files and tokenize it to store as a \".data\"\n",
    "midi_path = 'gct634-SMD-MIDI/'\n",
    "midi_files = list(find_files_by_extensions(midi_path, ['.mid']))\n",
    "\n",
    "save_path = 'gct634-SMD-data/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "out_fmt = '{}.data'\n",
    "\n",
    "for midi_file in midi_files:\n",
    "  pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "  instrument = pm.instruments[0]\n",
    "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "\n",
    "  # shift the first note to 0 sec\n",
    "  time_shift = sorted_notes[0].start\n",
    "  for note in sorted_notes:\n",
    "    note.start -= time_shift\n",
    "    note.end -= time_shift\n",
    "\n",
    "  # translates the note sequences into the four classes (NOTE_ON, NOTE_OFF, VELOCITY, and TIME_SHIFT) of events.\n",
    "  event_seq = EventSeq.from_note_seq(sorted_notes)\n",
    "\n",
    "  # encodes the four classes of events into token indices.\n",
    "  event_data = event_seq.to_array()\n",
    "\n",
    "  # save the tokenized file\n",
    "  name = os.path.basename(midi_file).split('.')[0]\n",
    "  save_name = os.path.join(save_path,out_fmt.format(name))\n",
    "  torch.save(event_data, save_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPphgSr91ROF"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747006485112,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "fs9gwGt41Ryd"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EventDataset(Dataset):\n",
    "    def __init__(self, window_size):\n",
    "        super(EventDataset, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.data_path = 'gct634-SMD-data/'\n",
    "        self.data_list = list(find_files_by_extensions(self.data_path, ['.data']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = os.path.join(self.data_list[idx])\n",
    "        data = torch.load(file_name, weights_only=False)\n",
    "        random_int = random.randint(0, len(data) - self.window_size)\n",
    "        data = data[random_int:random_int+self.window_size]\n",
    "        return torch.LongTensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIVefdE4HgXO"
   },
   "source": [
    "## Build the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747006485118,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "dL2XKwxwGin6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel as P\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_layers, n_hidden, n_dict, n_enc_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.n_dict = n_dict\n",
    "\n",
    "        # define encoder\n",
    "        self.encoder = nn.Embedding(self.n_dict, n_enc_dim)\n",
    "\n",
    "        # define rnn cell\n",
    "        self.rnn = nn.LSTM(input_size= n_enc_dim,\n",
    "                           hidden_size=self.n_hidden,\n",
    "                           num_layers=self.n_layers,\n",
    "                           batch_first=True)\n",
    "\n",
    "        # define decoder\n",
    "        self.decoder = nn.Linear(in_features=self.n_hidden,\n",
    "                                 out_features=self.n_dict)\n",
    "\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, hidden, tau):\n",
    "        # TO DO: incoporate tau into the following code\n",
    "        x_encoder = self.encoder(x)\n",
    "        x_encoder, x_hidden = self.rnn(x_encoder, hidden)\n",
    "        x_decoder = self.decoder(x_encoder)\n",
    "        x_decoder = x_decoder / tau # temperature scaling\n",
    "        x_pred = self.log_softmax(x_decoder)\n",
    "\n",
    "        return x_pred, x_hidden\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_layers, n_hidden, n_dict, n_enc_dim):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.model = LSTM(n_layers, n_hidden, n_dict, n_enc_dim)\n",
    "\n",
    "    def forward(self, x, hidden, tau):\n",
    "         return self.model(x, hidden, tau)\n",
    "\n",
    "    def init_hidden(self, batch_size, random_init=True):\n",
    "        if random_init:\n",
    "            return torch.randn(self.n_layers, batch_size, self.n_hidden), \\\n",
    "                   torch.randn(self.n_layers, batch_size, self.n_hidden)\n",
    "        else:\n",
    "            return torch.zeros(self.n_layers, batch_size, self.n_hidden), \\\n",
    "                   torch.zeros(self.n_layers, batch_size, self.n_hidden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OprQ30B5Kh_W"
   },
   "source": [
    "## Train  the Model\n",
    "\n",
    "This cell is the main part to train the model using data loaders and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747006485139,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "TOls0ttlGigV"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Runner(object):\n",
    "    def __init__(self, model, lr, weight_decay):\n",
    "      self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "      self.scheduler = StepLR(self.optimizer, step_size=1000, gamma=0.98)\n",
    "      self.learning_rate = lr\n",
    "      self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "      self.model = model.to(self.device)\n",
    "      self.criterion = nn.NLLLoss().to(self.device)\n",
    "\n",
    "    def train(self, dataloader):\n",
    "\n",
    "      train_batch_num = len(dataloader)\n",
    "      self.model.train()\n",
    "\n",
    "      for batch_idx, batch_data in enumerate(dataloader):\n",
    "        batch_data = batch_data.to(self.device)\n",
    "        batch_c0, batch_h0 = self.model.init_hidden(batch_data.shape[0])\n",
    "        init_hidden = (batch_c0.to(self.device), batch_h0.to(self.device))\n",
    "        batch_hidden = init_hidden\n",
    "\n",
    "        # forward\n",
    "        pred, _ = self.model(x=batch_data[:, :-1], hidden=batch_hidden, tau = 1.0)\n",
    "        pred, target = pred.reshape(-1, pred.shape[-1]), batch_data[:, 1:].reshape(-1)\n",
    "        loss = self.criterion(pred, target)\n",
    "\n",
    "        # backward\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "\n",
    "      return batch_idx, train_batch_num, loss.item()\n",
    "\n",
    "    def test(self, sequence, tau):\n",
    "      with torch.no_grad():\n",
    "        self.model.eval()\n",
    "\n",
    "        batch_c0, batch_h0 = self.model.init_hidden(batch_size=1, random_init=False)\n",
    "        init_hidden = (batch_c0.to(self.device), batch_h0.to(self.device))\n",
    "        init_pred = torch.zeros((1,), dtype=torch.long).to(self.device)\n",
    "\n",
    "        hidden = init_hidden\n",
    "        pred = init_pred\n",
    "        preds = []\n",
    "\n",
    "        for step in range(sequence - 1):\n",
    "          pred, hidden = self.model(x=pred.unsqueeze(0), hidden=hidden, tau=tau)\n",
    "          pred_dist = pred.data.view(-1).exp()\n",
    "          pred = torch.multinomial(pred_dist, 1)\n",
    "          preds.append(pred.cpu().numpy()[0])\n",
    "\n",
    "        return preds\n",
    "      \n",
    "    def test_primer(self, primer, sequence, tau):\n",
    "    # TO DO: implement the primed generation\n",
    "      with torch.no_grad():\n",
    "        self.model.eval()\n",
    "\n",
    "        # regenerate the hidden state using the primer\n",
    "        batch_c0, batch_h0 = self.model.init_hidden(batch_size=1, random_init=False)\n",
    "        init_hidden = (batch_c0.to(self.device), batch_h0.to(self.device))\n",
    "        _, hidden = self.model(x=primer.unsqueeze(0).to(self.device), hidden=init_hidden, tau=tau)\n",
    "\n",
    "        # start generation from last token of primer\n",
    "        pred = primer[-1].unsqueeze(0).to(self.device)\n",
    "        preds = primer.tolist()\n",
    "        \n",
    "        for step in range(sequence - len(primer)):\n",
    "            pred, hidden = self.model(x=pred.unsqueeze(0), hidden=hidden, tau=tau)\n",
    "            pred_dist = pred.data.view(-1).exp()\n",
    "            pred = torch.multinomial(pred_dist, 1)\n",
    "            preds.append(pred.cpu().numpy()[0])\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1MuQnkmvT6F"
   },
   "source": [
    "Let's train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "executionInfo": {
     "elapsed": 5912,
     "status": "error",
     "timestamp": 1747006491054,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "eYas0OfcydW-",
    "outputId": "584885cb-b908-4590-99bc-77d1cd523ba7"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 48\n",
    "window_size = 200\n",
    "weight_decay = 0\n",
    "learning_rate = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "# LSTM spec\n",
    "LSTM_n_enc_dim = 240\n",
    "LSTM_n_layers = 3\n",
    "LSTM_n_hidden = 256\n",
    "LSTM_n_dict = 240\n",
    "\n",
    "# dataloader\n",
    "dataset = EventDataset(window_size)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# model\n",
    "model = Model(LSTM_n_layers, LSTM_n_hidden, LSTM_n_dict, LSTM_n_enc_dim)\n",
    "\n",
    "# dataloader\n",
    "runner = Runner(model=model, lr = learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  batch_idx, train_batch_num, train_loss = runner.train(train_loader)\n",
    "  if (epoch % 100) == 0:\n",
    "    print('Epoch: {:03d}/{:03d}, Loss: {:5f}'.format(epoch + 1, NUM_EPOCHS, train_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BVx5z2DuU9P"
   },
   "source": [
    "## Inference: Unconditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1747006491216,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "Wpo8sQggLYSr"
   },
   "outputs": [],
   "source": [
    "sequence = 4000\n",
    "tau = 1.0\n",
    "output_tokens = runner.test(sequence,tau)\n",
    "\n",
    "event_seq = EventSeq.from_array(output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "gen_midi.instruments.append(inst)\n",
    "\n",
    "synth_audio = gen_midi.fluidsynth(fs=sr)\n",
    "ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oDMs9vKTl6E"
   },
   "source": [
    "## Evaluating the Result Using Pitch, Step, and Duration Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 57348,
     "status": "aborted",
     "timestamp": 1747006491218,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "OJ-16UmMLmOi"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_distributions(notes: pd.DataFrame, drop_percentile=2.5):\n",
    "  plt.figure(figsize=[15, 5])\n",
    "  plt.subplot(1, 3, 1)\n",
    "  sns.histplot(notes, x=\"pitch\", bins=20)\n",
    "\n",
    "  plt.subplot(1, 3, 2)\n",
    "#  max_step = np.percentile(notes['step'], 100 - drop_percentile)\n",
    "  max_step = 0.5\n",
    "  sns.histplot(notes, x=\"step\", bins=np.linspace(0, max_step, 21))\n",
    "\n",
    "  plt.subplot(1, 3, 3)\n",
    "#  max_duration = np.percentile(notes['duration'], 100 - drop_percentile)\n",
    "  max_duration = 2.0\n",
    "  sns.histplot(notes, x=\"duration\", bins=np.linspace(0, max_duration, 21))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naHGNiHL1gS5"
   },
   "source": [
    "This is the statistics of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 57339,
     "status": "aborted",
     "timestamp": 1747006491219,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "5r-8MpJWk-e1"
   },
   "outputs": [],
   "source": [
    "midi_file = 'gct634-SMD-MIDI/Bach_BWV888-01_008_20110315-SMD.mid'\n",
    "pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "raw_notes = midi_to_notes(pm)\n",
    "plot_distributions(raw_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCjeZR_txPgS"
   },
   "source": [
    "Plot the statistics of the generated music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 57339,
     "status": "aborted",
     "timestamp": 1747006491221,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "YQeCuAlDk-UF"
   },
   "outputs": [],
   "source": [
    "gen_notes = midi_to_notes(gen_midi)\n",
    "plot_distributions(gen_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "eps = 1e-9\n",
    "\n",
    "def normalize_hist(hist):\n",
    "    hist = hist.astype(np.float64)\n",
    "    return hist / (np.sum(hist) + eps)\n",
    "\n",
    "def histogram_distance(p_hist, q_hist):\n",
    "    p = normalize_hist(p_hist)\n",
    "    q = normalize_hist(q_hist)\n",
    "\n",
    "    distances = {\n",
    "        \"L1\": np.sum(np.abs(p - q)),\n",
    "        \"L2\": np.sqrt(np.sum((p - q)**2)),\n",
    "        \"KL(p||q)\": entropy(p + eps, q + eps),\n",
    "        \"KL(q||p)\": entropy(q + eps, p + eps),\n",
    "    }\n",
    "    \n",
    "    distances[\"average\"] = np.mean(list(distances.values()))\n",
    "\n",
    "    return distances\n",
    "\n",
    "def histogram_distance_notes(raw_notes, gen_notes):\n",
    "    result = {}\n",
    "    for key in raw_notes.keys():\n",
    "        p = np.histogram(raw_notes[key])[0]\n",
    "        q = np.histogram(gen_notes[key])[0]\n",
    "        result[key] = histogram_distance(p, q)\n",
    "    return result\n",
    "  \n",
    "def print_histogram_distance(raw_notes, gen_notes):\n",
    "    dist = histogram_distance_notes(raw_notes, gen_notes)\n",
    "    average = np.mean([v[\"average\"] for v in dist.values()])\n",
    "    for key, value in dist.items():\n",
    "        print(key)\n",
    "        for k, v in value.items():\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "    print(f\"Average distance: {average:.4f}\")\n",
    "            \n",
    "print_histogram_distance(raw_notes, gen_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbvM7BxZe7ZZ"
   },
   "source": [
    "## Conditional Generation with a Primer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 57333,
     "status": "aborted",
     "timestamp": 1747006491224,
     "user": {
      "displayName": "Jooeun Lim",
      "userId": "06828287337566885605"
     },
     "user_tz": -540
    },
    "id": "iSwnimjGe-XN"
   },
   "outputs": [],
   "source": [
    "sequence = 4000\n",
    "tau = 1.0\n",
    "\n",
    "date_file = 'gct634-SMD-data/Bach_BWV888-01_008_20110315-SMD.data'\n",
    "primer_data = torch.load(date_file, weights_only=False)\n",
    "\n",
    "primer = primer_data[:100]\n",
    "primer_output_tokens = runner.test_primer(torch.LongTensor(primer), sequence, tau)\n",
    "primer_output_tokens = list(primer) + primer_output_tokens\n",
    "\n",
    "event_seq = EventSeq.from_array(primer_output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "primer_gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "primer_gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(primer_gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "synth_audio = primer_gen_midi.fluidsynth(fs=sr)\n",
    "ipd.Audio(synth_audio, rate=sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu0ozAseCnrU"
   },
   "source": [
    "# Credit\n",
    "\n",
    "This homework is based on a PerformanceRNN implementation on this Github reposity (https://github.com/hmi88/prnn/tree/master).   \n",
    "\n",
    "The orignial code was modified by Juhan Nam, Hounsu Kim, Jaeran Choi from the KAIST Music and Audio Computing Lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tau optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tau = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditional generation\n",
    "sequence = 4000\n",
    "tau = 0.8\n",
    "output_tokens = runner.test(sequence,tau)\n",
    "\n",
    "event_seq = EventSeq.from_array(output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "synth_audio = gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conditional generation\n",
    "# date_file = 'gct634-SMD-data/Bach_BWV888-01_008_20110315-SMD.data'\n",
    "# primer_data = torch.load(date_file, weights_only=False)\n",
    "\n",
    "# primer = primer_data[:100]\n",
    "# primer_output_tokens = runner.test_primer(torch.LongTensor(primer), sequence, tau)\n",
    "# primer_output_tokens = list(primer) + primer_output_tokens\n",
    "\n",
    "# event_seq = EventSeq.from_array(primer_output_tokens)\n",
    "# output_notes = event_seq.to_note_seq()\n",
    "# velocity_scale=0.8\n",
    "\n",
    "# # restore the velocity scale\n",
    "# for note in output_notes:\n",
    "#   note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# # make a prettyMIDI object\n",
    "# primer_gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "# inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "# inst.notes = copy.deepcopy(output_notes)\n",
    "# primer_gen_midi.instruments.append(inst)\n",
    "\n",
    "# gen_notes = midi_to_notes(primer_gen_midi)\n",
    "# plot_distributions(gen_notes)\n",
    "# print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "# synth_audio = primer_gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tau = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditional generation\n",
    "sequence = 4000\n",
    "tau = 0.8\n",
    "output_tokens = runner.test(sequence,tau)\n",
    "\n",
    "event_seq = EventSeq.from_array(output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "synth_audio = gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conditional generation\n",
    "# date_file = 'gct634-SMD-data/Bach_BWV888-01_008_20110315-SMD.data'\n",
    "# primer_data = torch.load(date_file, weights_only=False)\n",
    "\n",
    "# primer = primer_data[:100]\n",
    "# primer_output_tokens = runner.test_primer(torch.LongTensor(primer), sequence, tau)\n",
    "# primer_output_tokens = list(primer) + primer_output_tokens\n",
    "\n",
    "# event_seq = EventSeq.from_array(primer_output_tokens)\n",
    "# output_notes = event_seq.to_note_seq()\n",
    "# velocity_scale=0.8\n",
    "\n",
    "# # restore the velocity scale\n",
    "# for note in output_notes:\n",
    "#   note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# # make a prettyMIDI object\n",
    "# primer_gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "# inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "# inst.notes = copy.deepcopy(output_notes)\n",
    "# primer_gen_midi.instruments.append(inst)\n",
    "\n",
    "# gen_notes = midi_to_notes(primer_gen_midi)\n",
    "# plot_distributions(gen_notes)\n",
    "# print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "# synth_audio = primer_gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tau = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditional generation\n",
    "sequence = 4000\n",
    "tau = 0.8\n",
    "output_tokens = runner.test(sequence,tau)\n",
    "\n",
    "event_seq = EventSeq.from_array(output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "synth_audio = gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conditional generation\n",
    "# date_file = 'gct634-SMD-data/Bach_BWV888-01_008_20110315-SMD.data'\n",
    "# primer_data = torch.load(date_file, weights_only=False)\n",
    "\n",
    "# primer = primer_data[:100]\n",
    "# primer_output_tokens = runner.test_primer(torch.LongTensor(primer), sequence, tau)\n",
    "# primer_output_tokens = list(primer) + primer_output_tokens\n",
    "\n",
    "# event_seq = EventSeq.from_array(primer_output_tokens)\n",
    "# output_notes = event_seq.to_note_seq()\n",
    "# velocity_scale=0.8\n",
    "\n",
    "# # restore the velocity scale\n",
    "# for note in output_notes:\n",
    "#   note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# # make a prettyMIDI object\n",
    "# primer_gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "# inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "# inst.notes = copy.deepcopy(output_notes)\n",
    "# primer_gen_midi.instruments.append(inst)\n",
    "\n",
    "# gen_notes = midi_to_notes(primer_gen_midi)\n",
    "# plot_distributions(gen_notes)\n",
    "# print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "# synth_audio = primer_gen_midi.fluidsynth(fs=sr)\n",
    "# # ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tau = 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditional generation\n",
    "sequence = 4000\n",
    "tau = 0.8\n",
    "output_tokens = runner.test(sequence,tau)\n",
    "\n",
    "event_seq = EventSeq.from_array(output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "synth_audio = gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conditional generation\n",
    "# date_file = 'gct634-SMD-data/Bach_BWV888-01_008_20110315-SMD.data'\n",
    "# primer_data = torch.load(date_file, weights_only=False)\n",
    "\n",
    "# primer = primer_data[:100]\n",
    "# primer_output_tokens = runner.test_primer(torch.LongTensor(primer), sequence, tau)\n",
    "# primer_output_tokens = list(primer) + primer_output_tokens\n",
    "\n",
    "# event_seq = EventSeq.from_array(primer_output_tokens)\n",
    "# output_notes = event_seq.to_note_seq()\n",
    "# velocity_scale=0.8\n",
    "\n",
    "# # restore the velocity scale\n",
    "# for note in output_notes:\n",
    "#   note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# # make a prettyMIDI object\n",
    "# primer_gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "# inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "# inst.notes = copy.deepcopy(output_notes)\n",
    "# primer_gen_midi.instruments.append(inst)\n",
    "\n",
    "# gen_notes = midi_to_notes(primer_gen_midi)\n",
    "# plot_distributions(gen_notes)\n",
    "# print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "# synth_audio = primer_gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tempo Conditioning + augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def find_files_by_extensions(root, exts=[]):\n",
    "    def _has_ext(name):\n",
    "        if not exts:\n",
    "            return True\n",
    "        name = name.lower()\n",
    "        for ext in exts:\n",
    "            if name.endswith(ext):\n",
    "                return True\n",
    "        return False\n",
    "    for path, _, files in os.walk(root):\n",
    "        for name in files:\n",
    "            if _has_ext(name):\n",
    "                yield os.path.join(path, name)\n",
    "                \n",
    "# Load MIDI files and tokenize it to store as a \".data\"\n",
    "midi_path = 'gct634-SMD-MIDI/'\n",
    "midi_files = list(find_files_by_extensions(midi_path, ['.mid']))\n",
    "\n",
    "save_path = 'gct634-SMD-data/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "out_fmt = '{}{}.data'\n",
    "\n",
    "# Tempo augmentation \n",
    "tempo_factors = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "\n",
    "for midi_file in midi_files:\n",
    "    pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "    instrument = pm.instruments[0]\n",
    "    sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "\n",
    "    # shift the first note to 0 sec\n",
    "    time_shift = sorted_notes[0].start\n",
    "    for note in sorted_notes:\n",
    "        note.start -= time_shift\n",
    "        note.end -= time_shift\n",
    "\n",
    "    base_name = os.path.basename(midi_file).split('.')[0]\n",
    "    \n",
    "    for tempo_factor in tempo_factors:\n",
    "        aug_notes = []\n",
    "        for note in sorted_notes:\n",
    "            aug_note = pretty_midi.Note(\n",
    "                velocity=note.velocity,\n",
    "                pitch=note.pitch,\n",
    "                start=note.start * tempo_factor,\n",
    "                end=note.end * tempo_factor\n",
    "            )\n",
    "            aug_notes.append(aug_note)\n",
    "\n",
    "        # translates the note sequences into the four classes (NOTE_ON, NOTE_OFF, VELOCITY, and TIME_SHIFT) of events.\n",
    "        event_seq = EventSeq.from_note_seq(aug_notes)\n",
    "\n",
    "        # encodes the four classes of events into token indices.\n",
    "        event_data = event_seq.to_array()\n",
    "\n",
    "        # save the tokenized file\n",
    "        suffix = '' if tempo_factor == 1.0 else f'_tempo{tempo_factor}'\n",
    "        save_name = os.path.join(save_path, out_fmt.format(base_name, suffix))\n",
    "        torch.save(event_data, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch\n",
    "\n",
    "class TempoAugDataset(Dataset):\n",
    "    def __init__(self, window_size, augment_tempo=True):\n",
    "        super(TempoAugDataset, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.data_path = 'gct634-SMD-data/'\n",
    "        self.data_list = list(find_files_by_extensions(self.data_path, ['.data']))\n",
    "        if not augment_tempo:\n",
    "            self.data_list = [f for f in self.data_list if '_tempo' not in f]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = os.path.join(self.data_list[idx])\n",
    "        data = torch.load(file_name, weights_only=False)\n",
    "\n",
    "        random_int = random.randint(0, len(data) - self.window_size)\n",
    "        data = data[random_int:random_int+self.window_size]\n",
    "        \n",
    "        # Extract tempo factor from filename\n",
    "        base_name = os.path.basename(file_name)\n",
    "        tempo_factor = float(base_name.split('_tempo')[1].split('.data')[0]) if '_tempo' in base_name else 1.0\n",
    "        \n",
    "        return torch.LongTensor(data), torch.FloatTensor([tempo_factor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel as P\n",
    "\n",
    "class TempoLSTM(nn.Module):\n",
    "    def __init__(self, n_layers, n_hidden, n_dict, n_enc_dim, tempo_cond=True):\n",
    "        super(TempoLSTM, self).__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.n_dict = n_dict\n",
    "        self.n_enc_dim = n_enc_dim\n",
    "        self.tempo_cond = tempo_cond\n",
    "\n",
    "        # define encoder\n",
    "        self.encoder = nn.Embedding(self.n_dict, n_enc_dim)\n",
    "\n",
    "        # Tempo embedding\n",
    "        if self.tempo_cond:\n",
    "            self.tempo_proj = nn.Linear(1, n_enc_dim)\n",
    "\n",
    "        # define rnn cell\n",
    "        self.rnn = nn.LSTM(input_size= n_enc_dim,\n",
    "                           hidden_size=self.n_hidden,\n",
    "                           num_layers=self.n_layers,\n",
    "                           batch_first=True)\n",
    "\n",
    "        # define decoder\n",
    "        self.decoder = nn.Linear(in_features=self.n_hidden,\n",
    "                                 out_features=self.n_dict)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, hidden, tau, tempo=None):\n",
    "      \n",
    "        x_encoder = self.encoder(x)\n",
    "\n",
    "        # Tempo embedding\n",
    "        if self.tempo_cond:\n",
    "            if isinstance(tempo, float):\n",
    "                tempo = torch.FloatTensor([tempo]).unsqueeze(0).to(x_encoder.device)\n",
    "            elif isinstance(tempo, torch.Tensor) and len(tempo.shape) == 1:\n",
    "                tempo = tempo.unsqueeze(1)\n",
    "            tempo_emb = self.tempo_proj(tempo)\n",
    "            tempo_emb = tempo_emb.unsqueeze(1).expand_as(x_encoder)\n",
    "            x_encoder = x_encoder + tempo_emb\n",
    "\n",
    "        x_encoder, x_hidden = self.rnn(x_encoder, hidden)\n",
    "        x_decoder = self.decoder(x_encoder) / tau  # temperature scaling\n",
    "        x_pred = self.log_softmax(x_decoder)\n",
    "\n",
    "        return x_pred, x_hidden\n",
    "\n",
    "\n",
    "class TempoModel(nn.Module):\n",
    "    def __init__(self, n_layers, n_hidden, n_dict, n_enc_dim, tempo_cond=True):\n",
    "        super(TempoModel, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.model = TempoLSTM(n_layers, n_hidden, n_dict, n_enc_dim, tempo_cond)\n",
    "\n",
    "    def forward(self, x, hidden, tau, tempo=None):\n",
    "        return self.model(x, hidden, tau, tempo)\n",
    "\n",
    "    def init_hidden(self, batch_size, random_init=True):\n",
    "        if random_init:\n",
    "            return torch.randn(self.n_layers, batch_size, self.n_hidden), \\\n",
    "                   torch.randn(self.n_layers, batch_size, self.n_hidden)\n",
    "        else:\n",
    "            return torch.zeros(self.n_layers, batch_size, self.n_hidden), \\\n",
    "                   torch.zeros(self.n_layers, batch_size, self.n_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class TempoRunner(object):\n",
    "    def __init__(self, model, lr, weight_decay):\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size=1000, gamma=0.98)\n",
    "        self.learning_rate = lr\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.criterion = nn.NLLLoss().to(self.device)\n",
    "\n",
    "    def train(self, dataloader):\n",
    "      \n",
    "        train_batch_num = len(dataloader)\n",
    "        self.model.train()\n",
    "\n",
    "        for batch_idx, (batch_data, batch_tempo) in enumerate(dataloader):\n",
    "            batch_tempo = batch_tempo.to(self.device)\n",
    "            batch_data = batch_data.to(self.device)\n",
    "            batch_c0, batch_h0 = self.model.init_hidden(batch_data.shape[0])\n",
    "            init_hidden = (batch_c0.to(self.device), batch_h0.to(self.device))\n",
    "            batch_hidden = init_hidden\n",
    "\n",
    "            # forward\n",
    "            pred, _ = self.model(x=batch_data[:, :-1], hidden=batch_hidden, tau=1.0, tempo=batch_tempo)\n",
    "            pred, target = pred.reshape(-1, pred.shape[-1]), batch_data[:, 1:].reshape(-1)\n",
    "            loss = self.criterion(pred, target)\n",
    "\n",
    "            # backward\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "\n",
    "        return batch_idx, train_batch_num, loss.item()\n",
    "\n",
    "    def test(self, sequence, tau, tempo=1.0):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "\n",
    "            batch_c0, batch_h0 = self.model.init_hidden(batch_size=1, random_init=False)\n",
    "            init_hidden = (batch_c0.to(self.device), batch_h0.to(self.device))\n",
    "            init_pred = torch.zeros((1,), dtype=torch.long).to(self.device)\n",
    "\n",
    "            hidden = init_hidden\n",
    "            pred = init_pred\n",
    "            preds = []\n",
    "\n",
    "            for step in range(sequence - 1):\n",
    "                pred, hidden = self.model(x=pred.unsqueeze(0), hidden=hidden, tau=tau, tempo=tempo)\n",
    "                pred_dist = pred.data.view(-1).exp()\n",
    "                pred = torch.multinomial(pred_dist, 1)\n",
    "                preds.append(pred.cpu().numpy()[0])\n",
    "\n",
    "            return preds\n",
    "\n",
    "      \n",
    "    def test_primer(self, primer, sequence, tau, tempo=1.0):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "\n",
    "            # regenerate the hidden state using the primer\n",
    "            batch_c0, batch_h0 = self.model.init_hidden(batch_size=1, random_init=False)\n",
    "            init_hidden = (batch_c0.to(self.device), batch_h0.to(self.device))\n",
    "            _, hidden = self.model(x=primer.unsqueeze(0).to(self.device), hidden=init_hidden, tau=tau, tempo=tempo)\n",
    "\n",
    "            # start generation from last token of primer\n",
    "            pred = primer[-1].unsqueeze(0).to(self.device)\n",
    "            preds = primer.tolist()\n",
    "            \n",
    "            for step in range(sequence - len(primer)):\n",
    "                pred, hidden = self.model(x=pred.unsqueeze(0), hidden=hidden, tau=tau, tempo=tempo)\n",
    "                pred_dist = pred.data.view(-1).exp()\n",
    "                pred = torch.multinomial(pred_dist, 1)\n",
    "                preds.append(pred.cpu().numpy()[0])\n",
    "\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 48\n",
    "window_size = 200\n",
    "weight_decay = 0\n",
    "learning_rate = 1e-3\n",
    "NUM_EPOCHS = 10000\n",
    "\n",
    "# LSTM spec\n",
    "LSTM_n_enc_dim = 240\n",
    "LSTM_n_layers = 3\n",
    "LSTM_n_hidden = 256\n",
    "LSTM_n_dict = 240\n",
    "\n",
    "# dataloader\n",
    "dataset = TempoAugDataset(window_size)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# model\n",
    "model = TempoModel(LSTM_n_layers, LSTM_n_hidden, LSTM_n_dict, LSTM_n_enc_dim)\n",
    "\n",
    "# dataloader\n",
    "runner = TempoRunner(model=model, lr = learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  batch_idx, train_batch_num, train_loss = runner.train(train_loader)\n",
    "  if (epoch % 100) == 0:\n",
    "    print('Epoch: {:03d}/{:03d}, Loss: {:5f}'.format(epoch + 1, NUM_EPOCHS, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer: Unconditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 4000\n",
    "tau = 1.0\n",
    "output_tokens = runner.test(sequence,tau)\n",
    "\n",
    "event_seq = EventSeq.from_array(output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "synth_audio = gen_midi.fluidsynth(fs=sr)\n",
    "ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer: Conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 4000\n",
    "tau = 1.0\n",
    "\n",
    "date_file = 'gct634-SMD-data/Bach_BWV888-01_008_20110315-SMD.data'\n",
    "primer_data = torch.load(date_file, weights_only=False)\n",
    "\n",
    "primer = primer_data[:100]\n",
    "primer_output_tokens = runner.test_primer(torch.LongTensor(primer), sequence, tau)\n",
    "primer_output_tokens = list(primer) + primer_output_tokens\n",
    "\n",
    "event_seq = EventSeq.from_array(primer_output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "primer_gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "primer_gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(primer_gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "synth_audio = primer_gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only tempo conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "dataset = TempoAugDataset(window_size, augment_tempo=False)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# model\n",
    "model = TempoModel(LSTM_n_layers, LSTM_n_hidden, LSTM_n_dict, LSTM_n_enc_dim, tempo_cond=True)\n",
    "\n",
    "# dataloader\n",
    "runner = TempoRunner(model=model, lr = learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  batch_idx, train_batch_num, train_loss = runner.train(train_loader)\n",
    "  if (epoch % 100) == 0:\n",
    "    print('Epoch: {:03d}/{:03d}, Loss: {:5f}'.format(epoch + 1, NUM_EPOCHS, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 4000\n",
    "tau = 1.0\n",
    "output_tokens = runner.test(sequence,tau)\n",
    "\n",
    "event_seq = EventSeq.from_array(output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "synth_audio = gen_midi.fluidsynth(fs=sr)\n",
    "ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 4000\n",
    "tau = 1.0\n",
    "\n",
    "date_file = 'gct634-SMD-data/Bach_BWV888-01_008_20110315-SMD.data'\n",
    "primer_data = torch.load(date_file, weights_only=False)\n",
    "\n",
    "primer = primer_data[:100]\n",
    "primer_output_tokens = runner.test_primer(torch.LongTensor(primer), sequence, tau)\n",
    "primer_output_tokens = list(primer) + primer_output_tokens\n",
    "\n",
    "event_seq = EventSeq.from_array(primer_output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "primer_gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "primer_gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(primer_gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "synth_audio = primer_gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only tempo augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "dataset = TempoAugDataset(window_size, augment_tempo=True)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# model\n",
    "model = TempoModel(LSTM_n_layers, LSTM_n_hidden, LSTM_n_dict, LSTM_n_enc_dim, tempo_cond=False)\n",
    "\n",
    "# dataloader\n",
    "runner = TempoRunner(model=model, lr = learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  batch_idx, train_batch_num, train_loss = runner.train(train_loader)\n",
    "  if (epoch % 100) == 0:\n",
    "    print('Epoch: {:03d}/{:03d}, Loss: {:5f}'.format(epoch + 1, NUM_EPOCHS, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditional generation\n",
    "sequence = 4000\n",
    "tau = 1.0\n",
    "output_tokens = runner.test(sequence,tau)\n",
    "\n",
    "event_seq = EventSeq.from_array(output_tokens)\n",
    "output_notes = event_seq.to_note_seq()\n",
    "velocity_scale=0.8\n",
    "\n",
    "# restore the velocity scale\n",
    "for note in output_notes:\n",
    "  note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# make a prettyMIDI object\n",
    "gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "inst.notes = copy.deepcopy(output_notes)\n",
    "gen_midi.instruments.append(inst)\n",
    "\n",
    "gen_notes = midi_to_notes(gen_midi)\n",
    "plot_distributions(gen_notes)\n",
    "print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "synth_audio = gen_midi.fluidsynth(fs=sr)\n",
    "ipd.Audio(synth_audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conditional generation\n",
    "# date_file = 'gct634-SMD-data/Bach_BWV888-01_008_20110315-SMD.data'\n",
    "# primer_data = torch.load(date_file, weights_only=False)\n",
    "\n",
    "# primer = primer_data[:100]\n",
    "# primer_output_tokens = runner.test_primer(torch.LongTensor(primer), sequence, tau)\n",
    "# primer_output_tokens = list(primer) + primer_output_tokens\n",
    "\n",
    "# event_seq = EventSeq.from_array(primer_output_tokens)\n",
    "# output_notes = event_seq.to_note_seq()\n",
    "# velocity_scale=0.8\n",
    "\n",
    "# # restore the velocity scale\n",
    "# for note in output_notes:\n",
    "#   note.velocity = int((note.velocity - 64) * velocity_scale + 64)\n",
    "\n",
    "# # make a prettyMIDI object\n",
    "# primer_gen_midi = PrettyMIDI(resolution=DEFAULT_RESOLUTION, initial_tempo=DEFAULT_TEMPO)\n",
    "# inst = Instrument(DEFAULT_SAVING_PROGRAM, False, 'NoteSeq')\n",
    "# inst.notes = copy.deepcopy(output_notes)\n",
    "# primer_gen_midi.instruments.append(inst)\n",
    "\n",
    "# gen_notes = midi_to_notes(primer_gen_midi)\n",
    "# plot_distributions(gen_notes)\n",
    "# print_histogram_distance(raw_notes, gen_notes)\n",
    "\n",
    "# synth_audio = primer_gen_midi.fluidsynth(fs=sr)\n",
    "# ipd.Audio(synth_audio, rate=sr)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1IMO3X_alaGrUUnf8koM7TaBecLhM7QEV",
     "timestamp": 1747006360963
    },
    {
     "file_id": "1pGIaIs33swOilhIw8zjB-VGcVQxuweph",
     "timestamp": 1745800832099
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
